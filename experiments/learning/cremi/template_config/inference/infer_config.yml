dataset_name: B

# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size
  window_size:
    A: [30, 540, 540]
    B: [30, 540, 540]
    C: [30, 540, 540]
#    A: [25, 1032, 1032]
#    B: [25, 1032, 1032]
#    C: [25, 1032, 1032]
  # Sliding window stride
  stride:
    A: [20, 360, 360]
    B: [20, 360, 360]
    C: [20, 360, 360]
#    A: [15, 600, 600]
#    B: [15, 600, 600]
#    C: [15, 600, 600]
  # Sliding window downsampling ratio. The actual image size along a
  # dimension is the window_size divided by the downsampling ratio.
  # Example:
  #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
  #   slice shape = [1, 256, 256]
  downsampling_ratio:
    A: [1, 1, 1]
    B: [1, 1, 1]
    C: [1, 1, 1]
  # Reflect padding on the loaded volume. Follows numpy.pad semantics.
  padding:
    A: [[5, 5], [80, 80], [80, 80]]
    B: [[5, 5], [80, 80], [80, 80]]
    C: [[5, 5], [80, 80], [80, 80]]
#    A: [[4, 4], [100, 100], [100, 100]]
#    B: [[4, 4], [100, 100], [100, 100]]
#    C: [[4, 4], [100, 100], [100, 100]]
  # Data slice to iterate over.
  data_slice:
    A: ':, :, :'
    B: ':, :, :'
    C: ':, :, :'


## Specify paths to volumes
#volume_config:
#  # Raw data
#  raw:
#    path:
#      A: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleA_train.h5'
#      B: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleB_train.h5'
#      C: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleC_train.h5'
#    path_in_h5_dataset:
#      A: 'raw'
#      B: 'raw'
#      C: 'raw'
##    ignore_slice_list:
##      B: [15, 16, 44, 45, 77]
##      C: [14, 74, 86]
##      # with added padding (5)
##      B: [20, 21, 49, 50, 82]
##      C: [19, 79, 91]
#    # Optionally, we specify training precision
#    dtype: float32
#  init_segmentation:
#    dtype: float32
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
#    # CREMI default is '/volumes/labels/neuron_ids'
#    path_in_h5_dataset:
#      A: 'finalSegm_WS'
#      B: 'finalSegm_WS_full'
#      C: 'finalSegm_WS'


defect_augmentation_config:
  p_artifact_source: 0
  p_deformed_slice: 0
  p_low_contrast: 0
  p_missing_slice: 0

loader_config:
  batch_size: 1
  drop_last: false
  num_workers: 12
  pin_memory: true

infer_config:
  augmentation_config: null
#  blending_config: {dim: 3, ramp_size: [4, 50, 50]}
  crop_padding: True
  gpu: 0
  num_workers: 5