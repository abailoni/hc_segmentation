# Config for pretraining AND training.

# Specify the names of the datasets
dataset_names:
  - A
  - B
  - C

# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size
  window_size:
    A: [25, 478, 478]
    B: [25, 478, 478]
    C: [25, 478, 478]
#    A: [25, 956, 956]
#    B: [25, 956, 956]
#    C: [25, 956, 956]
  # Sliding window stride
  stride:
    A: [1, 222, 222]
    B: [1, 222, 222]
    C: [1, 222, 222]
#    A: [1, 430, 430]
#    B: [1, 430, 430]
#    C: [1, 430, 430]
#    A: [1, 444, 444]
#    B: [1, 444, 444]
#    C: [1, 444, 444]
  # Example:
  #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
  #   slice shape = [1, 256, 256]
  downsampling_ratio:
    A: [1, 1, 1]
    B: [1, 1, 1]
    C: [1, 1, 1]
  # Reflect padding on the loaded volume. Follows numpy.pad semantics.
  # IMPORTANT no reflect padding along z !
  padding:
    A: [[5, 0], [50, 50], [50, 50]]
    B: [[5, 0], [50, 50], [50, 50]]
    C: [[5, 0], [50, 50], [50, 50]]
  # Data slice to iterate over.
  data_slice:
    A: '85:, :, :'
    B: '85:, :, :'
    C: '85:, :, :'

#    slicing_config_affs:
#    # Sliding window size
#    window_size:
#      A: [3, 25, 444, 444]
#      B: [3, 25, 444, 444]
#      C: [3, 25, 444, 444]
#    # Sliding window stride
#    stride:
#      A: [3, 1, 444, 444]
#      B: [3, 1, 444, 444]
#      C: [3, 1, 444, 444]
#    # Sliding window downsampling ratio. The actual image size along a
#    # dimension is the window_size divided by the downsampling ratio.
#    # Example:
#    #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
#    #   slice shape = [1, 256, 256]
#    downsampling_ratio:
#      A: [1, 1, 2, 2]
#      B: [1, 1, 2, 2]
#      C: [1, 1, 2, 2]
#    # Reflect padding on the loaded volume. Follows numpy.pad semantics.
#    padding:
#      A: [[0,0], [5, 0], [50, 50], [50, 50]]
#      B: [[0,0], [5, 0], [50, 50], [50, 50]]
#      C: [[0,0], [5, 0], [50, 50], [50, 50]]
#    # Data slice to iterate over.
#    data_slice:
#      A: ':, 85:, :, :'
#      B: ':, 85:, :, :'
#      C: ':, 85:, :, :'
    
defect_augmentation_config:
    p_missing_slice: 0.025
    p_low_contrast: 0.025
    p_deformed_slice: 0.0
    p_artifact_source: 0
    deformation_mode: 'compress'
    deformation_strenght: 20
    # these are mean and std-val of sample A (no defects)
    #mean_val: 126.16258056554555 
    #std_val: 27.726422228789211
#    artifact_source:
#        min_masking_ratio: .5
#        slicing_config:
#          window_size: [1, 478, 478]
#          stride: [1, 222, 222]
#        volume_config:
#          artifacts:
#            path: '/export/home/abailoni/datasets/cremi/constantin_data/sample_ABC_padded_20160501.defects.hdf'
#            path_in_h5_dataset: 'defect_sections/raw'
#            dtype: float32
#          alpha_mask:
#            path: '/export/home/abailoni/datasets/cremi/constantin_data/sample_ABC_padded_20160501.defects.hdf'
#            path_in_h5_dataset: 'defect_sections/mask'
#        master_config:
#          elastic_transform:
#            alpha: 2000.
#            sigma: 50.

# Specify paths to volumes
volume_config:
  # Raw data
  raw:
    path:
      A: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleA_train.h5'
      B: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleB_train.h5'
      C: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleC_train.h5'
    path_in_h5_dataset:
      A: 'raw'
      B: 'raw'
      C: 'raw'
    ignore_slice_list:
      B: [15, 16, 44, 45, 77]
      C: [14, 74, 86]
#      # with added padding (5)
#      B: [20, 21, 49, 50, 82]
#      C: [19, 79, 91]
    # Optionally, we specify training precision
    dtype: float32
  # Membranes
#  segmFinal:
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
#    # CREMI default is '/volumes/labels/neuron_ids'
#    path_in_h5_dataset:
#      A: 'finalSegm_WS'
#      B: 'finalSegm_WS_full'
#      C: 'finalSegm_WS'
#    dtype: float32
#  underSegm:
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
#    # CREMI default is '/volumes/labels/neuron_ids'
#    path_in_h5_dataset:
#      A: 'finalSegm_WS'
#      B: 'finalSegm_WS_full'
#      C: 'finalSegm_WS'
#    dtype: float32
#  segmFinal:
#    path:
#      A: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/thrsh010_A/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/thrsh010_B/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/thrsh010_C/pred_segm.h5'
#    path_in_h5_dataset:
#      A: 'finalSegm'
#      B: 'finalSegm'
#      C: 'finalSegm'
#    dtype: int32
#  underSegm:
#    path:
#      A: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/full_thrsh020_A/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/full_thrsh020_B/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/input_segm/WSDT_DS1/postprocess/full_thrsh020_C/pred_segm.h5'
#    path_in_h5_dataset:
#      A: 'finalSegm'
#      B: 'finalSegm'
#      C: 'finalSegm'
#    dtype: int32
#  GT:
#    dtype: float32
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleA/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleB/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleC/pred_segm.h5'
#    path_in_h5_dataset: {A: 'finalSegm_best_GT', B: 'finalSegm_best_GT', C: 'finalSegm_best_GT'}
  GT:
    dtype: int32
    path:
      A: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleA_train.h5'
      B: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleB_train.h5'
      C: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleC_train.h5'
    path_in_h5_dataset: {A: 'segmentations/groundtruth_fixed', B: 'segmentations/groundtruth_fixed', C: 'segmentations/groundtruth_fixed'}
#  init_segmentation:
#    dtype: int32
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleA/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleB/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/WSDTplusHC_thrsh090_sampleC/pred_segm.h5'
#    path_in_h5_dataset: {A: 'finalSegm', B: 'finalSegm', C: 'finalSegm'}



# Configuration for the master dataset.
master_config:
  # We might need order 0 interpolation if we have segmentation in there somewhere.
  elastic_transform:
    alpha: 2000.
    sigma: 50.
    order: 0
  # we crop to get rid of the elastic augment reflection padding
  # and the invalid affinities (that's why we have additional lowe z crop)
  crop_after_target:
    crop_left: [5, 50, 50]
    crop_right: [0, 50, 50]
  random_slides: False
#  shape_after_slide: [478, 478]

offsets: [[-1, 0, 0], [0, -1, 0], [0, 0, -1], [-2, 0, 0], [0, -3, 0], [0, 0, -3], [-3, 0, 0],
                    [0, -9, 0], [0, 0, -9], [-4, 0, 0], [0, -27, 0], [0, 0, -27]]
    
# Specify configuration for the loader
loader_config:
  # Number of processes to use for loading data. Set to (say) 10 if you wish to
  # use 10 CPU cores, or to 0 if you wish to use the same process for training and
  # data-loading (generally not recommended).
  batch_size: 2
  num_workers: 40
  drop_last: True
  pin_memory: True
  shuffle: True
