# Specify the names of the datasets
dataset_names:
  - A
  - B
  - C

# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size
  window_size:
    A: [25, 444, 444]
    B: [25, 444, 444]
    C: [25, 444, 444]
#    A: [25, 848, 848]
#    B: [25, 848, 848]
#    C: [25, 848, 848]
  # Sliding window stride
  stride:
    A: [1, 222, 222]
    B: [1, 222, 222]
    C: [1, 222, 222]
#    A: [1, 444, 444]
#    B: [1, 444, 444]
#    C: [1, 444, 444]
  # Sliding window downsampling ratio. The actual image size along a
  # dimension is the window_size divided by the downsampling ratio.
  # Example:
  #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
  #   slice shape = [1, 256, 256]
  downsampling_ratio:
    A: [1, 1, 1]
    B: [1, 1, 1]
    C: [1, 1, 1]
  # Reflect padding on the loaded volume. Follows numpy.pad semantics.
  padding:
    A: [[5, 0], [50, 50], [50, 50]]
    B: [[5, 0], [50, 50], [50, 50]]
    C: [[5, 0], [50, 50], [50, 50]]
  # Data slice to iterate over.
  data_slice:
    A: '0:65, :, :'
    B: '0:65, :, :'
    C: '0:65, :, :'

  slicing_config_affs:
    # Sliding window size
    window_size:
      A: [3, 25, 848, 848]
      B: [3, 25, 848, 848]
      C: [3, 25, 848, 848]
    # Sliding window stride
    stride:
      A: [3, 1, 444, 444]
      B: [3, 1, 444, 444]
      C: [3, 1, 444, 444]
    # Sliding window downsampling ratio. The actual image size along a
    # dimension is the window_size divided by the downsampling ratio.
    # Example:
    #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
    #   slice shape = [1, 256, 256]
    downsampling_ratio:
      A: [1, 1, 2, 2]
      B: [1, 1, 2, 2]
      C: [1, 1, 2, 2]
    # Reflect padding on the loaded volume. Follows numpy.pad semantics.
    padding:
      A: [[0,0], [5, 0], [50, 50], [50, 50]]
      B: [[0,0], [5, 0], [50, 50], [50, 50]]
      C: [[0,0], [5, 0], [50, 50], [50, 50]]
    # Data slice to iterate over.
    data_slice:
      A: ':, 0:65, :, :'
      B: ':, 0:65, :, :'
      C: ':, 0:65, :, :'
    
defect_augmentation_config:
    p_missing_slice: 0.03
    p_low_contrast: 0.03
    p_deformed_slice: 0.0
    p_artifact_source: 0
    deformation_mode: 'compress'
    deformation_strenght: 20
#    artifact_source:
#        min_masking_ratio: .5
#        slicing_config:
#          window_size: [1, 444, 444]
#          stride: [1, 444, 444]
#          downsampling_ratio: [1, 1, 1]
#        volume_config:
#          artifacts:
#            path: '/export/home/abailoni/datasets/cremi/constantin_data/sample_ABC_padded_20160501.defects.hdf'
#            path_in_h5_dataset: 'defect_sections/raw'
#            dtype: float32
#          alpha_mask:
#            path: '/export/home/abailoni/datasets/cremi/constantin_data/sample_ABC_padded_20160501.defects.hdf'
#            path_in_h5_dataset: 'defect_sections/mask'
#        master_config:
#          elastic_transform:
#            alpha: 2000.
#            sigma: 50.

# Specify paths to volumes
volume_config:
  # Raw data
  raw:
    path:
      A: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleA_train.h5'
      B: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleB_train.h5'
      C: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleC_train.h5'
    path_in_h5_dataset:
      A: 'raw'
      B: 'raw'
      C: 'raw'
    ignore_slice_list:
      B: [15, 16, 44, 45, 77]
      C: [14, 74, 86]
#      # with added padding (5)
#      B: [20, 21, 49, 50, 82]
#      C: [19, 79, 91]
    # Optionally, we specify training precision
    dtype: float32
  init_segmentation:
    path:
      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
    # CREMI default is '/volumes/labels/neuron_ids'
    path_in_h5_dataset:
      A: 'finalSegm_WS'
      B: 'finalSegm_WS_full'
      C: 'finalSegm_WS'
    dtype: uint32
#  init_boundaries:
#    path:
#      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
#      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
#      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
#    # CREMI default is '/volumes/labels/neuron_ids'
#    path_in_h5_dataset:
#      A: 'boundary_IDs'
#      B: 'boundary_IDs'
#      C: 'boundary_IDs'
  GT:
    path:
      A: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullA_thresh093_blckws/pred_segm.h5'
      B: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullB_thresh093_blckws_1/pred_segm.h5'
      C: '/export/home/abailoni/learnedHC/new_experiments/SOA_affinities/postprocess/fancyOverseg_betterWeights_fullC_thresh093_blckws/pred_segm.h5'
    # CREMI default is '/volumes/labels/neuron_ids'
    path_in_h5_dataset:
      A: 'finalSegm_WS_best_GT'
      B: 'finalSegm_WS_best_GT_full'
      C: 'finalSegm_WS_best_GT'
    # Specify training precision
    dtype: uint32
#  GT:
#    path:
#      A: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleA_train.h5'
#      B: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleB_train.h5'
#      C: '/export/home/abailoni/datasets/cremi/SOA_affinities/sampleC_train.h5'
#    # CREMI default is '/volumes/labels/neuron_ids'
#    path_in_h5_dataset:
#      A: 'segmentations/groundtruth_fixed'
#      B: 'segmentations/groundtruth_fixed'
#      C: 'segmentations/groundtruth_fixed'

offsets: [[-1, 0, 0], [0, -1, 0], [0, 0, -1], [-2, 0, 0], [0, -3, 0], [0, 0, -3], [-3, 0, 0],
                    [0, -9, 0], [0, 0, -9], [-4, 0, 0], [0, -27, 0], [0, 0, -27]]

# Configuration for the master dataset.
master_config:
  rejection_threshold: 0.5
  # We might need order 0 interpolation if we have segmentation in there somewhere.
  elastic_transform:
    alpha: 2000.
    sigma: 50.
    order: 0
  # we crop to get rid of the elastic augment reflection padding
  # and the invalid affinities (that's why we have additional lower z crop)
  crop_after_target:
    crop_left: [5, 50, 50]
    crop_right: [0, 50, 50]
  affinities_on_gpu: False
  random_slides: True
  shape_after_slide: [424, 424]


# Specify configuration for the loader
loader_config:
  # Number of processes to use for loading data. Set to (say) 10 if you wish to
  # use 10 CPU cores, or to 0 if you wish to use the same process for training and
  # data-loading (generally not recommended).
  batch_size: 2
  num_workers: 40
  drop_last: True
  pin_memory: True
  shuffle: True
